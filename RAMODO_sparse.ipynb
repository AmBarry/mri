{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cgroza/ramodo/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.set_random_seed(42)\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "from keras import backend as K\n",
    "#K.set_session(sess)\n",
    "\n",
    "from keras.layers import Input, Dense, Layer\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors, KDTree\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from utilities import dataLoading, cutoff_unsorted, aucPerformance, \\\n",
    "    normalization, writeRepresentation,writeResults, writeOutlierScores,visualizeData\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_INT = np.iinfo(np.int32).max\n",
    "\n",
    "epoch_num = \"100e\"\n",
    "\n",
    "#@mem.cache\n",
    "def get_data_from_svmlight_file(path):\n",
    "    \"\"\"extract data from svmlight files\n",
    "    \"\"\"\n",
    "    data = load_svmlight_file(path)\n",
    "    return data[0], data[1]\n",
    "\n",
    "def get_priorknowledge_from_svmlight_file(path):\n",
    "    \"\"\"obtain prior knowledge from the news20 data.\n",
    "    the news20 data set is converted to an outlier detection data set by \n",
    "    downsampling the positive class (i.e., the outlier class) such that \n",
    "    the positive class accounts for only 2% data objects in the converted\n",
    "    data set. The prior knowledge is the rest of positive objects.\n",
    "    Specifically, below nm denotes the number of positive objects used as\n",
    "    outliers, and otl = otl[nm:] selects the rest of positive objects as the \n",
    "    pool of prior knowledge.\n",
    "    \"\"\"\n",
    "    data = load_svmlight_file(path)\n",
    "    X = data[0]\n",
    "    y = data[1]\n",
    "    neg = np.where(y[y==-1])[0].shape[0]\n",
    "    print(neg) \n",
    "    otl = np.where(y==1)[0]\n",
    "    nm = int(neg / 0.98) - neg\n",
    "    otl = otl[nm:]\n",
    "    X =X[otl, :]\n",
    "    y = y[otl]\n",
    "    return X, y\n",
    "\n",
    "def readMatdata(path):\n",
    "    url = loadmat(path)\n",
    "    X = url['data']\n",
    "    y = url['labels']\n",
    "    return X, y\n",
    "    \n",
    "def sqr_euclidean_dist(x,y):\n",
    "    return K.sum(K.square(x - y), axis=-1);\n",
    "  \n",
    "\n",
    "class tripletRankingLossLayer(Layer):\n",
    "    \"\"\"Triplet ranking loss layer Class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(tripletRankingLossLayer, self).__init__(**kwargs)\n",
    "        \n",
    "\n",
    "\n",
    "    def rankingLoss(self, input_example, input_positive, input_negative):\n",
    "        \"\"\"Return the mean of the triplet ranking loss\"\"\"\n",
    "        \n",
    "        positive_distances = sqr_euclidean_dist(input_example, input_positive)\n",
    "        negative_distances = sqr_euclidean_dist(input_example, input_negative)\n",
    "        \n",
    "        loss = K.mean(K.maximum(0., 1000. - (negative_distances - positive_distances) ))\n",
    "        return loss\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_example = inputs[0]\n",
    "        input_positive = inputs[1]\n",
    "        input_negative = inputs[2]\n",
    "        loss = self.rankingLoss(input_example, input_positive, input_negative)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return input_example;\n",
    "     \n",
    "def lesinn(x_train, issparse = False):\n",
    "    \"\"\"the outlier scoring method, a bagging ensemble of Sp. See the following reference for detail.\n",
    "    Pang, Guansong, Kai Ming Ting, and David Albrecht. \n",
    "    \"LeSiNN: Detecting anomalies by identifying least similar nearest neighbours.\" \n",
    "    In Data Mining Workshop (ICDMW), 2015 IEEE International Conference on, pp. 623-630. IEEE, 2015.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(42)\n",
    "    ensemble_size = 100\n",
    "    subsample_size = 50\n",
    "    scores = np.zeros([x_train.shape[0], 1])  \n",
    "    # for reproductibility purpose  \n",
    "    seeds = rng.randint(MAX_INT, size = ensemble_size)\n",
    "    for i in range(0, ensemble_size):\n",
    "        rs = np.random.RandomState(seeds[i])\n",
    "        sid = sample_without_replacement(n_population = x_train.shape[0], n_samples = subsample_size, random_state = rs)\n",
    "        subsample = x_train[sid]\n",
    "        dists = np.zeros([x_train.shape[0], 1])\n",
    "        if issparse:\n",
    "            dist_mat = pairwise_distances(x_train, subsample, metric='euclidean')\n",
    "            dists = np.amax(dist_mat, axis = 1).reshape(x_train.shape[0], 1)\n",
    "        else:\n",
    "            kdt = KDTree(subsample, metric='euclidean')\n",
    "            dists, indices = kdt.query(x_train, k = 1)\n",
    "        scores += dists\n",
    "    scores = scores / ensemble_size  \n",
    "    return scores;\n",
    "\n",
    "def batch_generator(X, labels, batch_size, steps_per_epoch, scores, rng, dk):\n",
    "    \"\"\"batch generator\n",
    "    \"\"\"\n",
    "    number_of_batches = steps_per_epoch\n",
    "    rng = np.random.RandomState(rng.randint(MAX_INT, size = 1))\n",
    "    counter = 0\n",
    "    while 1:\n",
    "        X1, X2, X3 = tripletBatchGeneration(X, batch_size, rng, scores, dk)\n",
    "        counter += 1\n",
    "        yield([np.array(X1), np.array(X2), np.array(X3)], None)\n",
    "        if (counter > number_of_batches):\n",
    "            counter = 0\n",
    "\n",
    "\n",
    "def tripletBatchGeneration(X, batch_size,  rng, outlier_scores, prior_knowledge = None):\n",
    "    \"\"\"batch generation\n",
    "    \"\"\"\n",
    "    inlier_ids, outlier_ids = cutoff_unsorted(outlier_scores)\n",
    "    transforms = np.sum(outlier_scores[inlier_ids]) - outlier_scores[inlier_ids]\n",
    "    total_weights_p = np.sum(transforms)\n",
    "    positive_weights = transforms / total_weights_p\n",
    "    positive_weights = positive_weights.flatten()\n",
    "    total_weights_n = np.sum(outlier_scores[outlier_ids])\n",
    "    negative_weights = outlier_scores[outlier_ids] / total_weights_n\n",
    "    negative_weights = negative_weights.flatten()\n",
    "    examples_ids = np.zeros([batch_size]).astype('int')\n",
    "    positives_ids = np.zeros([batch_size]).astype('int')\n",
    "    negatives_ids = np.zeros([batch_size]).astype('int')\n",
    "    for i in range(0, batch_size):\n",
    "        sid = rng.choice(len(inlier_ids), 1, p = positive_weights)\n",
    "        examples_ids[i] = inlier_ids[sid]\n",
    "        sid2 = rng.choice(len(inlier_ids), 1)\n",
    "        \n",
    "        while sid2 == sid:\n",
    "            sid2 = rng.choice(len(inlier_ids), 1)\n",
    "            \n",
    "        positives_ids[i] = inlier_ids[sid2]\n",
    "        if (prior_knowledge is not None) & (i % 2 == 0):\n",
    "            did = rng.choice(prior_knowledge.shape[0], 1)      \n",
    "            negatives_ids[i] = did\n",
    "        else:\n",
    "            sid = rng.choice(len(outlier_ids), 1, p = negative_weights)\n",
    "            negatives_ids[i] = outlier_ids[sid]\n",
    "    csr = X.tocsr()  \n",
    "    examples = csr[examples_ids, :].toarray()\n",
    "    positives = csr[positives_ids, :].toarray()\n",
    "    negatives = np.zeros([batch_size, X.shape[1]])        \n",
    "    if prior_knowledge is not None:       \n",
    "        negatives[1::2] = csr[negatives_ids[1::2], :].toarray()        \n",
    "        negatives[::2] = prior_knowledge.tocsr()[negatives_ids[::2], :].toarray()      \n",
    "    else:\n",
    "        negatives = csr[negatives_ids, :].toarray()                     \n",
    "    return examples, positives, negatives;\n",
    "            \n",
    "            \n",
    "def tripletModel(input_dim, embedding_size):\n",
    "    \"\"\"the learning model\n",
    "    \"\"\"\n",
    "    \n",
    "    input_e = Input(shape=(input_dim,), name = 'input_e')\n",
    "    input_p = Input(shape=(input_dim,), name = 'input_p')\n",
    "    input_n = Input(shape=(input_dim,), name = 'input_n')\n",
    "    \n",
    "    hidden_layer = Dense(embedding_size, activation='relu', name = 'hidden_layer')\n",
    "    hidden_e = hidden_layer(input_e)\n",
    "    hidden_p = hidden_layer(input_p)\n",
    "    hidden_n = hidden_layer(input_n)\n",
    "    \n",
    "    output_layer = tripletRankingLossLayer()([hidden_e,hidden_p,hidden_n])    \n",
    "    rankModel = Model(inputs=[input_e, input_p, input_n], outputs=output_layer)    \n",
    "    representation = Model(inputs=input_e, outputs=hidden_e)\n",
    "    \n",
    "    print(rankModel.summary(), representation.summary())    \n",
    "    return rankModel, representation;\n",
    "\n",
    "def training_model(rankModel, X, labels, embedding_size, scores, filename, ite_num, rng = None, prior_knowledge = None):\n",
    "    \"\"\"training the model\n",
    "    \"\"\"\n",
    "    \n",
    "    rankModel.compile(optimizer = 'adadelta', loss = None)\n",
    "    checkpointer = ModelCheckpoint(\"./model/\" + str(embedding_size) + \"D_\"  + str(ite_num) +  \"_\" + epoch_num + filename + \".h5\", monitor='loss',\n",
    "                               verbose=0, save_best_only = True, save_weights_only=True)\n",
    "    if rng == None:\n",
    "        rng = np.random.RandomState(42) \n",
    "        \n",
    "    batch_size = 256    \n",
    "    #samples_per_epoch = 5000 \n",
    "    samples_per_epoch = X.shape[0]\n",
    "    steps_per_epoch = samples_per_epoch / batch_size\n",
    "    history = rankModel.fit_generator(batch_generator(X, labels, batch_size, steps_per_epoch, scores, rng, prior_knowledge),\n",
    "                           steps_per_epoch = steps_per_epoch,\n",
    "                              epochs = 20,\n",
    "                              shuffle = False,\n",
    "                              callbacks=[checkpointer])\n",
    "\n",
    "def makePrediction(X, representation, embedding_size):\n",
    "    \"\"\"learn the low-dimensional representations\n",
    "    \"\"\"\n",
    "    \n",
    "    data_size = X.shape[0]\n",
    "    new_data = np.zeros([data_size, embedding_size])\n",
    "    count = 64\n",
    "    i = 0\n",
    "    # batch-based mapping of ultrahigh-dimensional data objects\n",
    "    # out-of-memory errors otherwise.\n",
    "    while i < data_size:\n",
    "        x = X[i:count].toarray()\n",
    "        new_data[i:count] = representation.predict(x)\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        i = count\n",
    "        count += 64\n",
    "        if count > data_size:\n",
    "            count = data_size\n",
    "    return new_data;\n",
    "\n",
    "\n",
    "def load_model_predict(model_name, X, labels, embedding_size, filename, label_number = None):\n",
    "    \"\"\"load the representation learning model and do the mappings.\n",
    "    LeSiNN, the Sp ensemble, is applied to perform outlier scoring\n",
    "    in the representation space.\n",
    "    \"\"\"\n",
    "    \n",
    "    rankModel, representation = tripletModel(X.shape[1], embedding_size=embedding_size)  \n",
    "    rankModel.load_weights(model_name)\n",
    "    representation = Model(inputs=rankModel.input[0],\n",
    "                                 outputs=rankModel.get_layer('hidden_layer').get_output_at(0))\n",
    "    \n",
    "    new_X = makePrediction(X, representation, embedding_size)\n",
    "#    writeRepresentation(new_X, labels, embedding_size, filename + str(embedding_size) + \"D_\" + str(label_number) + \"_\" + epoch_num)\n",
    "    scores = lesinn(new_X)\n",
    "    rauc = aucPerformance(scores, labels)\n",
    "#    writeResults(filename + str(embedding_size) + \"D_\"  + epoch_num , embedding_size, rauc)\n",
    "#    writeResults(filename + str(embedding_size) + \"D_\" +dk + str(label_number) + \"_\" + epoch_num , embedding_size, rauc)\n",
    "#    writeOutlierScores(scores, labels, str(embedding_size)+ \"D_\" + dk + str(label_number) + \"_\" + epoch_num + filename)\n",
    "    return rauc\n",
    "        \n",
    "    \n",
    "def test_diff_embeddings(X, labels, outlier_scores, filename):\n",
    "    \"\"\"sensitivity test w.r.t. different representation dimensions\n",
    "    \"\"\"\n",
    "    embeddings = np.array([1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "    for j in range(0,len(embeddings)):\n",
    "        embedding_size = embeddings[j]\n",
    "        start_time = time.time()\n",
    "        test_single_embedding(X, labels, embedding_size, outlier_scores, filename)\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "def test_single_embedding(X, labels, embedding_size, outlier_scores, filename, prior_knowledge = None):\n",
    "    \"\"\"perform representation learning with a fixed representation dimension\n",
    "    and outlier detection using LeSiNN\n",
    "    \"\"\"\n",
    "    runs = 1\n",
    "    rauc = np.empty([runs, 1])\n",
    "    rng = np.random.RandomState(42) \n",
    "    for i in range(0,runs):\n",
    "        rankModel, representation = tripletModel(X.shape[1], embedding_size)\n",
    "        training_model(rankModel, X, labels, embedding_size, outlier_scores, filename, i, rng, prior_knowledge)\n",
    "        \n",
    "        modelName = \"model/\" + str(embedding_size) + \"D_\" +str(i)  + \"_\" + epoch_num + filename + '.h5'\n",
    "        rauc[i] = load_model_predict(modelName, X, labels, embedding_size, filename)\n",
    "    mean_auc = np.mean(rauc)\n",
    "    print(mean_auc)\n",
    "    return mean_auc;\n",
    "\n",
    "def selectPriorKnowledge(X, k, rng):\n",
    "    \"\"\"select the number of labeled outliers in the prior knowledge pool\n",
    "    \"\"\"\n",
    "    sid = rng.choice(X.shape[0], k, replace = False)\n",
    "    dk = X[sid]\n",
    "    return dk;\n",
    "\n",
    "def single_embedding_with_priorknowledge(X, labels, embedding_size, X_dk, outlier_scores, filename):\n",
    "    \"\"\"perform representation learning with a fixed representation dimension and prior knowledge\n",
    "    \"\"\"\n",
    "    label_numbers = np.array([X_dk.shape[0]])\n",
    "#    label_numbers = np.array([1, 5, 10, 20, 40, 80])\n",
    "    for i in range(0,label_numbers.shape[0]):\n",
    "        label_number = label_numbers[i]\n",
    "        rng = np.random.RandomState(42) \n",
    "        runs = 1\n",
    "        auc_array = np.zeros([runs, 1])\n",
    "        for j in range(0, runs):\n",
    "            prior_knowledge = selectPriorKnowledge(X_dk, label_number, rng)\n",
    "            auc_array[j] = test_single_embedding(X, labels,embedding_size, outlier_scores, filename, prior_knowledge)\n",
    "        #writeResults(filename + str(embedding_size) + \"D_\" + str(label_number) + \"_\" + epoch_num , embedding_size, np.mean(auc_array), np.std(auc_array))     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"Data Sets/K9.data\", header = None, na_values = [\"?\"])\n",
    "data = data[ data.columns[0:5409] ]\n",
    "data.dropna(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[5408].to_numpy()\n",
    "X = data[ data.columns[0:5408] ].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"active\" : 1, \"inactive\" : -1}\n",
    "labels = np.array([d[l] for l in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(labels == 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_scores = lesinn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 54.31742184],\n",
       "       [ 54.41154703],\n",
       "       [ 54.50739103],\n",
       "       ...,\n",
       "       [547.00292968],\n",
       "       [580.40540796],\n",
       "       [614.45651477]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(outlier_scores, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = np.where(labels[labels==-1])[0].shape[0]\n",
    "otl = np.where(labels==1)[0]\n",
    "nm = int(neg / 0.98) - neg\n",
    "otl = otl[:20]\n",
    "\n",
    "X_dk = X[otl, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5408)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "X_sparse = scipy.sparse.csc_matrix(X)\n",
    "X_dk_sparse = scipy.sparse.csc_matrix(X_dk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_e (InputLayer)            (None, 5408)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_p (InputLayer)            (None, 5408)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_n (InputLayer)            (None, 5408)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer (Dense)            (None, 20)           108180      input_e[0][0]                    \n",
      "                                                                 input_p[0][0]                    \n",
      "                                                                 input_n[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "triplet_ranking_loss_layer_5 (t [(None, 20), (None,  0           hidden_layer[0][0]               \n",
      "                                                                 hidden_layer[1][0]               \n",
      "                                                                 hidden_layer[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 108,180\n",
      "Trainable params: 108,180\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_e (InputLayer)         (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer (Dense)         (None, 20)                108180    \n",
      "=================================================================\n",
      "Total params: 108,180\n",
      "Trainable params: 108,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cgroza/ramodo/lib/python3.7/site-packages/keras/engine/training_utils.py:819: UserWarning: Output triplet_ranking_loss_layer_5 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to triplet_ranking_loss_layer_5.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "122/121 [==============================] - 1067s 9s/step - loss: 68.3854\n",
      "Epoch 2/20\n",
      "122/121 [==============================] - 1034s 8s/step - loss: 16.1663\n",
      "Epoch 3/20\n",
      "122/121 [==============================] - 1062s 9s/step - loss: 9.6210\n",
      "Epoch 4/20\n",
      "122/121 [==============================] - 1054s 9s/step - loss: 8.5417\n",
      "Epoch 5/20\n",
      "122/121 [==============================] - 1032s 8s/step - loss: 8.4436\n",
      "Epoch 6/20\n",
      "122/121 [==============================] - 1133s 9s/step - loss: 7.2127\n",
      "Epoch 7/20\n",
      "122/121 [==============================] - 1246s 10s/step - loss: 6.7167\n",
      "Epoch 8/20\n",
      "122/121 [==============================] - 1163s 10s/step - loss: 6.3480\n",
      "Epoch 9/20\n",
      "122/121 [==============================] - 1119s 9s/step - loss: 4.4592\n",
      "Epoch 10/20\n",
      "122/121 [==============================] - 1094s 9s/step - loss: 4.3894\n",
      "Epoch 11/20\n",
      "122/121 [==============================] - 1090s 9s/step - loss: 6.1630\n",
      "Epoch 12/20\n",
      "122/121 [==============================] - 1079s 9s/step - loss: 5.3558\n",
      "Epoch 13/20\n",
      "122/121 [==============================] - 1031s 8s/step - loss: 4.2124\n",
      "Epoch 14/20\n",
      "122/121 [==============================] - 1030s 8s/step - loss: 2.8280\n",
      "Epoch 15/20\n",
      "122/121 [==============================] - 1033s 8s/step - loss: 2.8000\n",
      "Epoch 16/20\n",
      "122/121 [==============================] - 1033s 8s/step - loss: 2.8702\n",
      "Epoch 17/20\n",
      "122/121 [==============================] - 1033s 8s/step - loss: 4.5827\n",
      "Epoch 18/20\n",
      "122/121 [==============================] - 1034s 8s/step - loss: 4.6058\n",
      "Epoch 19/20\n",
      "122/121 [==============================] - 1035s 8s/step - loss: 3.4804\n",
      "Epoch 20/20\n",
      "122/121 [==============================] - 1034s 8s/step - loss: 3.5230\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_e (InputLayer)            (None, 5408)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_p (InputLayer)            (None, 5408)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_n (InputLayer)            (None, 5408)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer (Dense)            (None, 20)           108180      input_e[0][0]                    \n",
      "                                                                 input_p[0][0]                    \n",
      "                                                                 input_n[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "triplet_ranking_loss_layer_6 (t [(None, 20), (None,  0           hidden_layer[0][0]               \n",
      "                                                                 hidden_layer[1][0]               \n",
      "                                                                 hidden_layer[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 108,180\n",
      "Trainable params: 108,180\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_e (InputLayer)         (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer (Dense)         (None, 20)                108180    \n",
      "=================================================================\n",
      "Total params: 108,180\n",
      "Trainable params: 108,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None None\n",
      "0\n",
      "8000\n",
      "16000\n",
      "24000\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'representation/p53_sparse20D_None_100e.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-14e826a513dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msingle_embedding_with_priorknowledge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_dk_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutlier_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"p53_sparse\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-056cdfea02aa>\u001b[0m in \u001b[0;36msingle_embedding_with_priorknowledge\u001b[0;34m(X, labels, embedding_size, X_dk, outlier_scores, filename)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mprior_knowledge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselectPriorKnowledge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mauc_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_single_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutlier_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_knowledge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0;31m#writeResults(filename + str(embedding_size) + \"D_\" + str(label_number) + \"_\" + epoch_num , embedding_size, np.mean(auc_array), np.std(auc_array))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-056cdfea02aa>\u001b[0m in \u001b[0;36mtest_single_embedding\u001b[0;34m(X, labels, embedding_size, outlier_scores, filename, prior_knowledge)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mmodelName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"D_\"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepoch_num\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mrauc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0mmean_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-056cdfea02aa>\u001b[0m in \u001b[0;36mload_model_predict\u001b[0;34m(model_name, X, labels, embedding_size, filename, label_number)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0mnew_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakePrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepresentation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0mwriteRepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"D_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_number\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlesinn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0mrauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maucPerformance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ramodo/utilities.py\u001b[0m in \u001b[0;36mwriteRepresentation\u001b[0;34m(data, labels, dim, name)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwriteResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./results/auc_performance.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ramodo/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m         )\n\u001b[0;32m-> 3204\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ramodo/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             )\n\u001b[1;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ramodo/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'representation/p53_sparse20D_None_100e.csv'"
     ]
    }
   ],
   "source": [
    "single_embedding_with_priorknowledge(X_sparse, labels, 20, X_dk_sparse, outlier_scores, \"p53_sparse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_e (InputLayer)            (None, 5408)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_p (InputLayer)            (None, 5408)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_n (InputLayer)            (None, 5408)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer (Dense)            (None, 20)           108180      input_e[0][0]                    \n",
      "                                                                 input_p[0][0]                    \n",
      "                                                                 input_n[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "triplet_ranking_loss_layer_10 ( [(None, 20), (None,  0           hidden_layer[0][0]               \n",
      "                                                                 hidden_layer[1][0]               \n",
      "                                                                 hidden_layer[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 108,180\n",
      "Trainable params: 108,180\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_e (InputLayer)         (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer (Dense)         (None, 20)                108180    \n",
      "=================================================================\n",
      "Total params: 108,180\n",
      "Trainable params: 108,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None None\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_population should be greater or equal than n_samples, got n_samples > n_population (50 > 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-b3e1bac92c02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_model_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model/20D_0_100ep53_sparse.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_dk_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model/20D_0_100ep53_sparse.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-53488ff951c8>\u001b[0m in \u001b[0;36mload_model_predict\u001b[0;34m(model_name, X, labels, embedding_size, filename, label_number)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0mnew_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakePrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepresentation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;31m#    writeRepresentation(new_X, labels, embedding_size, filename + str(embedding_size) + \"D_\" + str(label_number) + \"_\" + epoch_num)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlesinn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0mrauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maucPerformance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;31m#    writeResults(filename + str(embedding_size) + \"D_\"  + epoch_num , embedding_size, rauc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-53488ff951c8>\u001b[0m in \u001b[0;36mlesinn\u001b[0;34m(x_train, issparse)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0msid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_without_replacement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_population\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubsample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0msubsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/utils/_random.pyx\u001b[0m in \u001b[0;36msklearn.utils._random.sample_without_replacement\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msklearn/utils/_random.pyx\u001b[0m in \u001b[0;36msklearn.utils._random.sample_without_replacement\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msklearn/utils/_random.pyx\u001b[0m in \u001b[0;36msklearn.utils._random._sample_without_replacement_check_input\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_population should be greater or equal than n_samples, got n_samples > n_population (50 > 20)"
     ]
    }
   ],
   "source": [
    "load_model_predict(\"model/20D_0_100ep53_sparse.h5\", X_dk_sparse, labels, 20, \"model/20D_0_100ep53_sparse.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
